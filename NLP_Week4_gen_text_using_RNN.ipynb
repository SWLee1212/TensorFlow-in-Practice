{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Week4_gen_text_using_RNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SWLee1212/TensorFlow-in-Practice/blob/master/NLP_Week4_gen_text_using_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIlUMC6WjTte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow-gpu==2.0.0\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKgIXaSuj2OC",
        "colab_type": "code",
        "outputId": "4df854e3-0f04-41a0-e404-af1d78869b2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paoOSRYDj52x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVMWEWAqkZiy",
        "colab_type": "code",
        "outputId": "413bced4-5291-482f-e7d3-76b2ffe93901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 읽은 다음 파이썬 2와 호환되도록 디코딩합니다.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# 텍스트의 길이는 그 안에 있는 문자의 수입니다.\n",
        "print ('텍스트의 길이: {}자'.format(len(text)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "텍스트의 길이: 1115394자\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLrJ9OlFka9k",
        "colab_type": "code",
        "outputId": "92d9d521-76ec-41c5-ce01-a450972437ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "print(text[:200])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaZ0d2JAkkZy",
        "colab_type": "code",
        "outputId": "74daa308-ef04-4132-e692-f5be47082713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# 파일의 고유 문자수를 출력합니다.\n",
        "vocab = sorted(set(text))\n",
        "print ('고유 문자수 {}개'.format(len(vocab)))\n",
        "print(vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "고유 문자수 65개\n",
            "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlAWEYgKktaw",
        "colab_type": "code",
        "outputId": "28609c47-1c33-4727-c827-2a9f5fc77cb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# 고유 문자에서 인덱스로 매핑 생성\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "print(char2idx)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6QkmzuEljg4",
        "colab_type": "code",
        "outputId": "88535d22-c332-4aa6-96cb-3b7ea3b3bd58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(idx2char)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n' ' ' '!' '$' '&' \"'\" ',' '-' '.' '3' ':' ';' '?' 'A' 'B' 'C' 'D' 'E'\n",
            " 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W'\n",
            " 'X' 'Y' 'Z' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o'\n",
            " 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO6IHjrzltdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqQNUvszl0rB",
        "colab_type": "code",
        "outputId": "66b3d2f8-17c9-4c45-c1d9-21011dda0bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(text_as_int[:20])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6Ri13P3l38L",
        "colab_type": "code",
        "outputId": "b9114c83-ac76-4c94-848e-1ad690e26902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 텍스트에서 처음 13개의 문자가 숫자로 어떻게 매핑되었는지를 보여줍니다\n",
        "print ('{} ---- 문자들이 다음의 정수로 매핑되었습니다 ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'First Citizen' ---- 문자들이 다음의 정수로 매핑되었습니다 ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZf8fyNImHfw",
        "colab_type": "code",
        "outputId": "67e5752c-9e6e-4097-e834-f69a7793676a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# 단일 입력에 대해 원하는 문장의 최대 길이\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//seq_length\n",
        "\n",
        "# 훈련 샘플/타깃 만들기\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()])\n",
        "  \n",
        "print(\"{} of examples per epch\".format(examples_per_epoch))  "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            "11153 of examples per epch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EUqZWKnmq0d",
        "colab_type": "code",
        "outputId": "ee43c34e-9038-4c33-cc36-12fcc9003992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "print(sequences)\n",
        "for item in sequences.take(1):\n",
        "  print(len(item.numpy()))\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: (101,), types: tf.int64>\n",
            "101\n",
            "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-CAji9zxwOK",
        "colab_type": "code",
        "outputId": "ae8654e1-749d-4e38-f237-68784bd22019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(tf.data.experimental.cardinality(sequences).numpy())\n",
        "print(len(text_as_int)/101)\n",
        "print(examples_per_epoch)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11043\n",
            "11043.50495049505\n",
            "11153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYUphbbpnni5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w-pYtOUpm1n",
        "colab_type": "code",
        "outputId": "2ce06be3-2232-4a23-d795-1f78df2a6357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('입력 데이터: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('타깃 데이터: ', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 데이터:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "타깃 데이터:  'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFNarwNyppRi",
        "colab_type": "code",
        "outputId": "fb3f8ab8-1860-4ca2-d86a-33b59b870a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"{:4d}단계\".format(i))\n",
        "    print(\"  입력: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  예상 출력: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0단계\n",
            "  입력: 18 ('F')\n",
            "  예상 출력: 47 ('i')\n",
            "   1단계\n",
            "  입력: 47 ('i')\n",
            "  예상 출력: 56 ('r')\n",
            "   2단계\n",
            "  입력: 56 ('r')\n",
            "  예상 출력: 57 ('s')\n",
            "   3단계\n",
            "  입력: 57 ('s')\n",
            "  예상 출력: 58 ('t')\n",
            "   4단계\n",
            "  입력: 58 ('t')\n",
            "  예상 출력: 1 (' ')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzesenFPu6yu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d1c20b3-da27-4618-be55-bb6b49d2299c"
      },
      "source": [
        "# 배치 크기\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# 데이터셋을 섞을 버퍼 크기\n",
        "# (TF 데이터는 무한한 시퀀스와 함께 작동이 가능하도록 설계되었으며,\n",
        "# 따라서 전체 시퀀스를 메모리에 섞지 않습니다. 대신에,\n",
        "# 요소를 섞는 버퍼를 유지합니다).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2oxyNRnFy5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문자로 된 어휘 사전의 크기\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# 임베딩 차원\n",
        "embedding_dim = 256\n",
        "\n",
        "# RNN 유닛(unit) 개수\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPCTdnoCGAwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQi97ionGEsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1Dwz9NhGGQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bdb499c5-a20a-4b60-b1f8-24b47de14302"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Iy-8cUNLCfe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "a63e4169-cf6b-4f03-d21d-9be6d96e8d76"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  print(input_example_batch.shape)\n",
        "  print(target_example_batch.shape)\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100)\n",
            "(64, 100)\n",
            "(64, 100, 65)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4gW06XjLXC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "d2d0aa27-28a8-48da-e6d1-def2d3c17eff"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N1YiYxkPtcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "799f2e97-5b54-4c5f-b280-a46b5258402c"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "print(example_batch_predictions[0].shape,sampled_indices.shape )\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "print(sampled_indices.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 65) (100, 1)\n",
            "(100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5unEli32cUlP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "ddf3174d-1de5-48fb-ddcf-931d4f1638fd"
      },
      "source": [
        "print(example_batch_predictions[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.00115136 -0.00059436 -0.00134415 ... -0.00491749  0.00322246\n",
            "   0.00245086]\n",
            " [ 0.00241114  0.00694487 -0.00781566 ...  0.00059266  0.00262329\n",
            "  -0.00465093]\n",
            " [ 0.00419355  0.01063012 -0.00360911 ... -0.00411889 -0.00267353\n",
            "  -0.00835107]\n",
            " ...\n",
            " [-0.00250592  0.00896428 -0.00078815 ... -0.00857972  0.004391\n",
            "  -0.00278685]\n",
            " [-0.00523379  0.00935444  0.00346116 ... -0.01033749 -0.00089915\n",
            "  -0.00619626]\n",
            " [-0.00154993  0.0067698   0.00350821 ... -0.01002302 -0.00950833\n",
            "  -0.00515196]], shape=(100, 65), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXciHpYKcY2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1e43780a-1dc7-419e-9c27-83034b85076b"
      },
      "source": [
        "print(\"입력: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"예측된 다음 문자: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력: \n",
            " \" as you are weary of the weight,\\nRest you, whiles I lament King Henry's corse.\\n\\nGLOUCESTER:\\nStay, yo\"\n",
            "\n",
            "예측된 다음 문자: \n",
            " \"KslUcWDDVfJsjZHzfbwFzyglkkL$BAJLG& Z$rYpdlOo?O,?\\nzB?SHmqjOKEOe'Y$iIF&YbhfOF3BALah3bKiwmC\\nUucziFDsQup\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwvq-SmmffML",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "421176af-1817-4ba2-a682-7209817e67f5"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"예측 배열 크기(shape): \", example_batch_predictions.shape, \" # (배치 크기, 시퀀스 길이, 어휘 사전 크기\")\n",
        "print(\"스칼라 손실:          \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 배열 크기(shape):  (64, 100, 65)  # (배치 크기, 시퀀스 길이, 어휘 사전 크기\n",
            "스칼라 손실:           4.1738243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8U_njrmmqB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qop7UHULm5Qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 체크포인트가 저장될 디렉토리\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# 체크포인트 파일 이름\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEQckHJZnGNx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7f05767-1f2f-4b39-8abc-feb4f8ed17fb"
      },
      "source": [
        "EPOCHS=50\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "172/172 [==============================] - 33s 193ms/step - loss: 2.5839\n",
            "Epoch 2/50\n",
            "172/172 [==============================] - 31s 180ms/step - loss: 1.8893\n",
            "Epoch 3/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 1.6417\n",
            "Epoch 4/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 1.5069\n",
            "Epoch 5/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 1.4258\n",
            "Epoch 6/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 1.3679\n",
            "Epoch 7/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 1.3218\n",
            "Epoch 8/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 1.2831\n",
            "Epoch 9/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 1.2457\n",
            "Epoch 10/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 1.2104\n",
            "Epoch 11/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 1.1744\n",
            "Epoch 12/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 1.1378\n",
            "Epoch 13/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 1.1002\n",
            "Epoch 14/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 1.0603\n",
            "Epoch 15/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 1.0199\n",
            "Epoch 16/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.9781\n",
            "Epoch 17/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.9369\n",
            "Epoch 18/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.8957\n",
            "Epoch 19/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.8561\n",
            "Epoch 20/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.8158\n",
            "Epoch 21/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.7801\n",
            "Epoch 22/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.7454\n",
            "Epoch 23/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.7132\n",
            "Epoch 24/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.6856\n",
            "Epoch 25/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.6587\n",
            "Epoch 26/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.6349\n",
            "Epoch 27/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.6129\n",
            "Epoch 28/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.5937\n",
            "Epoch 29/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.5743\n",
            "Epoch 30/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.5588\n",
            "Epoch 31/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.5433\n",
            "Epoch 32/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.5314\n",
            "Epoch 33/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.5198\n",
            "Epoch 34/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.5095\n",
            "Epoch 35/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.4990\n",
            "Epoch 36/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.4911\n",
            "Epoch 37/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.4820\n",
            "Epoch 38/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.4736\n",
            "Epoch 39/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.4672\n",
            "Epoch 40/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.4640\n",
            "Epoch 41/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.4556\n",
            "Epoch 42/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.4523\n",
            "Epoch 43/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.4485\n",
            "Epoch 44/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.4424\n",
            "Epoch 45/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.4384\n",
            "Epoch 46/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.4353\n",
            "Epoch 47/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.4295\n",
            "Epoch 48/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.4299\n",
            "Epoch 49/50\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.4282\n",
            "Epoch 50/50\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.4260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxWCMxGSnMfF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d4536374-bdf1-4869-bb34-e0abf8e3a1c5"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)  \n",
        "  \n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "print(\"예측된 다음 문자: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측된 다음 문자: \n",
            " 'HIchard Gath best deserved df rll.my hons.\\n\\nut is your grace,dead  my Lord of Sometset?\\nONORFOLK:\\nHo'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMgBYS_SqXqD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f0cf5469-c24f-4cfc-8c1a-47d93abeb480"
      },
      "source": [
        "print(\"입력 라벨 문자: \\n\", repr(\"\".join(idx2char[target_example_batch[0].numpy()])))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 라벨 문자: \n",
            " 'Richard hath best deserved of all my sons.\\nBut is your grace dead, my Lord of Somerset?\\n\\nNORFOLK:\\nSu'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNYyv9IhqgEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "# acc=history.history['acc']\n",
        "# val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "# val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(loss)) # Get number of epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rAo93oGr5uX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "71cae862-1c8b-4afc-b3da-a7f11cf61e12"
      },
      "source": [
        "fig = go.Figure(\n",
        "    data = [go.Scatter(x=list(epochs), y=loss)]\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"faa06dd2-4f07-4f74-b9a3-b29776d3a0d2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"faa06dd2-4f07-4f74-b9a3-b29776d3a0d2\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'faa06dd2-4f07-4f74-b9a3-b29776d3a0d2',\n",
              "                        [{\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], \"y\": [2.583888925785242, 1.88832384001377, 1.641284743713778, 1.506611013828322, 1.4258501377216606, 1.3679058253765106, 1.3218695029269818, 1.2829198102618373, 1.2458686988021053, 1.2106793758481047, 1.1746447945750036, 1.137910317542941, 1.1002901917280152, 1.0605517854524213, 1.0199748132117958, 0.9783134398072265, 0.9370808351871579, 0.8959926332152167, 0.8564108620549358, 0.8159648121096367, 0.780415205414905, 0.7456045965122622, 0.7135227575551631, 0.6857486561287282, 0.6588653149299843, 0.6350615274074466, 0.6132239910752274, 0.594030655054159, 0.5746754258871078, 0.5589966067048007, 0.5435676082622173, 0.5316632053879804, 0.5200631391516951, 0.5096363170548927, 0.4992570015926694, 0.4913085901806521, 0.48231772610614465, 0.4738831986175027, 0.46752029986575594, 0.46418000549771066, 0.45579990675283033, 0.45257862865231757, 0.44869614375192063, 0.4427070707775826, 0.4385536387562752, 0.4355045411475869, 0.42969098895095115, 0.4300104126680729, 0.42834743181633395, 0.42620689525853755]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('faa06dd2-4f07-4f74-b9a3-b29776d3a0d2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8sMJDgVRcS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}